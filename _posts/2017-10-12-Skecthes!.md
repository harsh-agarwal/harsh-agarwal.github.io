---
layout: post
title : Delving into sketches! 
---

After my sophomore year I started working on sketches! Sketches are very different from images. Let's take an example to understand this. 

IMAGES TO EXPLAIN THE DIFFERENCE! 

Even though sketches are so different, yet humans are able to understand skecthes pretty intuitively and easily. There are some characteristic features that are involved with a particular type of sketches. we somhow have been trained to recognise such features given the enormous data that we have been fed with since our childhood! Can we expect a neural network to do that job? 

This was my project at IISc Bangalore, which I ended up getting after my quest of augmenting anything that we think about. You can read about that .......

The idea was to understand sketches in detail. So we started working on this project! How to approach this problem? The basic idea is that: 

> Images have too much of information and sketches have too sparse information. So we need to somehow decrease the information in the images and increase the information in a skecth to come to a mid level representation that can be used to compare these two entities! 

Simple enough! But how do we do it? We don't really have a dataset dedicated to sketch segmentation and annotation! So we started collecting dataset at the same time thinking about alternatives. 

After several failed attempts we finally decided to simply sketchify the images in PASCAL VOC Dataset. So in essence we brought image to the sketch embedding space. Now we can train this network on these transformed images. So we have: 

- 'skecthified' images
- parts correponding to these images so in essence we have parts form sketchified images as well! 

We finally got substantial data to train our network. Yipee! 

Quoting [Yoshua Bengio's answer to "Is fine tuning a pre-trained model equivalent to transfer learning?"](https://www.quora.com/Is-fine-tuning-a-pre-trained-model-equivalent-to-transfer-learning/answer/Yoshua-Bengio?srid=uRIUf): 

> Yes, if the data on which the model is fine-tuned is of a different nature from the original data used to pre-train the model. It is a form of transfer learning, and it has worked extremely well in many object classification tasks.

This was the "Eureka Moment!" So we started working in this direction. We had to do a couple of things before we could get this check our idea. Primarily: 


1. Get a suitable sketch like representation on which we could train the network.
2. Design a network to segment sketches pixel wise in a manner analogous to images. 

For the first part we started experimenting with various forms of sketches. Main questions that we had were: 

1. What if we ran just canny edge detector and trained the network! 
2. Can we add some more detail using part boundary explicitly? 
3. Can we design a deep network for sketchifying the images even? Like using DeepContours (PUT THE LINK TO THE PAPER)

For the network, we decided to use a standard network designed for image segmentation to start our experiments. DeepLabV2 (PUT THE LINK)

So let's take up the first question. What representation to choose? Well, we tried training some categories ('Cows' and 'Horses') with various representation that helped us in qualitatively decide which representations can we go for! wanna have a look? See!

<img width="868" alt="screen shot 2017-10-13 at 10 11 25 am" src="https://user-images.githubusercontent.com/11302053/31530959-812874ce-b001-11e7-94a3-48a25074fe5d.png">

Although the network was trained on cows and horses it performs reasonably on cats even:

<img width="495" alt="screen shot 2017-10-13 at 10 48 50 am" src="https://user-images.githubusercontent.com/11302053/31531332-1c4b24e0-b004-11e7-876d-019ee55683fb.png">




Looking at the above result we decided we would be using OB + PB + Canny and from skecthes in the following manner: 

<img width="868" alt="screen shot 2017-10-13 at 10 37 58 am" src="https://user-images.githubusercontent.com/11302053/31531100-7845216c-b002-11e7-8726-42e29b48496a.png">

So after preparing the images in the foellowing manner, we had to train this network for various categories. 





